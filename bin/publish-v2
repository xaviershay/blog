#!/usr/bin/env ruby

require "open3"
require 'yaml'
require 'pp'

config = YAML.load(File.read("s3_website.yml"))

local = "_site"
staging = "_staged"
bucket = config.fetch("s3_bucket")
cloudfront_id = config.fetch("cloudfront_distribution_id")
redirects = config.fetch("redirects", {})

cmds = []

# TODO: This approach always reuploads everything. Not what we want. I think
# sync uses mtime, so need a way of preserving that.

cmds << "rm -Rf %s" % staging
cmds << "bundle exec jekyll build"
cmds << "cp -R %s %s" % [local, staging]
cmds << "find %s -type f -exec gzip -n {} \\; -exec sh -c 'mv \"$1.gz\" \"${1%%}\"' -- {} \\;" % [staging]
cmds << "aws s3 sync %s s3://%s/ --content-encoding gzip" % [staging, bucket]
cmds << "aws cloudfront create-invalidation --distribution-id %s --paths \"/*\"" % [cloudfront_id]

if false
  redirects.each do |key, value|
    cmds << "aws s3api put-object --bucket %s --key %s --website-redirect-location %s" % [
      bucket,
      key,
      value
    ]
  end
else
  cmds << "echo Skipping redirects, edit script to change"
end

def run(command)
  Open3.popen2e(command) do |stdin, stdout_and_stderr, wait_thr|
    stdout_and_stderr.each_line do |line|
      puts line
    end

    exit_status = wait_thr.value
    unless exit_status.success?
      abort "Command failed with exit status #{exit_status.exitstatus}"
    end
  end
end

cmds.each do |cmd|
  puts cmd
  run(cmd)
end
